"""
æ™ºèƒ½å¡ç»„æ‰«æå™¨ V2
ä½¿ç”¨å›¾åƒè¯†åˆ«åŠ¨æ€æ£€æµ‹å¡ç‰‡ä½ç½®ï¼Œä¸ä¾èµ–å›ºå®šåæ ‡
"""
import time
import cv2
import numpy as np
from pathlib import Path
from loguru import logger
import json
import sys
sys.path.append(str(Path(__file__).parent.parent))

from src.vision.screen_capture import ScreenCapture
from src.control.mouse_controller import MouseController
from src.vision.card_detector import CardImageRecognizer


class SmartDeckScanner:
    """æ™ºèƒ½å¡ç»„æ‰«æå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ‰«æå™¨"""
        self.screen_capture = ScreenCapture("masterduel")
        # 1. é¼ æ ‡åŠ é€Ÿï¼šä½¿ç”¨ fastest ä¸”å‡å°‘ humanize å»¶è¿Ÿ
        self.mouse = MouseController(speed='fastest', humanize=False)
        self.recognizer = CardImageRecognizer()
        
        # 2. åŒºåŸŸè°ƒæ•´ï¼šå¿…é¡»é¿å¼€é¡¶éƒ¨çš„æŒ‰é’®ï¼ˆæ’¤é”€ã€åˆ é™¤ç­‰ï¼‰
        # ä¹‹å‰çš„ y_start=0.10 å¤ªé ä¸Šäº†ï¼ŒåŒ…å«äº†è§£æ•£å¡ç»„æŒ‰é’®
        self.deck_area = {
            'x_start': 0.25,  
            'x_end': 0.65,    # ä¿®å¤ï¼šæ’é™¤ç¬¬11åˆ—ï¼ˆé¢„è§ˆé¢æ¿ï¼‰
            'y_start': 0.18,  # ä¸‹ç§»é¿å¼€é¡¶éƒ¨å·¥å…·æ 
            'y_end': 0.96,    # ç¨å¾®åŠ æ·±
        }
        
        # å·¦ä¾§è¯¦æƒ…åŒºåŸŸ
        self.detail_area = {
            'x': 0.02,
            'y': 0.05,
            'width': 0.20,
            'height': 0.60
        }
        
    def scan_deck(self, deck_name: str = "auto_scan") -> dict:
        """æ™ºèƒ½æ‰«æå¡ç»„"""
        logger.info("=" * 60)
        logger.info(f"å¼€å§‹æ™ºèƒ½æ‰«æå¡ç»„: {deck_name}")
        logger.info("=" * 60)
        
        if not self.screen_capture.find_game_window():
            logger.error("æœªæ‰¾åˆ°æ¸¸æˆçª—å£ï¼")
            return None
        
        window_rect = self.screen_capture.window_rect
        self.window_x = window_rect[0]
        self.window_y = window_rect[1]
        
        screenshot = self.screen_capture.capture_window()
        if screenshot is None:
            logger.error("æˆªå›¾å¤±è´¥ï¼")
            return None
        
        logger.info("æ£€æµ‹å¡ç‰‡ä½ç½®...")
        card_positions = self._detect_card_positions(screenshot)
        
        logger.info(f"æ£€æµ‹åˆ° {len(card_positions)} ä¸ªå¯èƒ½çš„å¡ç‰‡ä½ç½®")
        
        if len(card_positions) == 0:
            logger.error("æœªæ£€æµ‹åˆ°å¡ç‰‡ï¼è¯·æ£€æŸ¥ debug_detection.png")
            return None
        
        deck_data = {
            'deck_name': deck_name,
            'cards': [],
            'timestamp': time.time()
        }
        
        # å»é‡é›†åˆ (åŸºäºä½ç½®)
        clicked_positions = set()
        
        for i, (cx, cy) in enumerate(card_positions, 1):
            # ç®€å•çš„è·ç¦»å»é‡ï¼Œé˜²æ­¢é‡å¤ç‚¹å‡»åŒä¸€å¼ å¡
            pos_key = (cx // 10, cy // 10) # 10åƒç´ ç½‘æ ¼å»é‡
            if pos_key in clicked_positions:
                continue
            clicked_positions.add(pos_key)
            
            # è¿›åº¦æ—¥å¿—
            if i % 5 == 0:
                logger.info(f"è¿›åº¦: {i}/{len(card_positions)}...")
            
            abs_x = self.window_x + cx
            abs_y = self.window_y + cy
            
            self.mouse.click(abs_x, abs_y)
            # å‡å°‘ç­‰å¾…æ—¶é—´ï¼š0.4s -> 0.15s (åªè¦ç•Œé¢åˆ·æ–°è¿™ä¸€ç¬é—´å°±è¡Œ)
            # å®é™…ä¸Šæ¸¸æˆé‡Œç‚¹å‡»å¡ç‰‡åˆ‡æ¢è¯¦æƒ…æ˜¯éå¸¸å¿«çš„
            time.sleep(0.15)
            
            detail_screenshot = self.screen_capture.capture_window()
            if detail_screenshot is None: continue
            
            # è¯†åˆ«å¡ç‰‡
            # æ—¢ç„¶OCRä¹±ç ï¼Œæˆ‘ä»¬è¿™é‡Œæš‚æ—¶åªè®°å½•ç´¢å¼•ï¼Œæˆ–è€…ç»™ä¸ªUnknownåå­—
            # é‡è¦çš„æ˜¯æˆ‘ä»¬æ‹¿åˆ°äº†å›¾ç‰‡æ¨¡æ¿
            card_info = self._recognize_card_from_detail(detail_screenshot)
            
            # å¦‚æœ OCR ç»“æœå¤ªä¹±ï¼Œå°±ç”¨ Card_Index ä¸´æ—¶å‘½å
            # é˜²æ­¢ JSON æ–‡ä»¶é‡Œå…¨æ˜¯ä¹±ç 
            final_name = card_info['name'] if card_info else f"Card_{i}"
            if "Card_" in final_name or len(final_name) > 20: 
                 # å¦‚æœåå­—è¿˜æ˜¯å¾ˆé•¿çš„ä¸€ä¸²ä¹±ç ï¼Œå¼ºåˆ¶æ”¹å
                 if len(final_name) > 30 or any(c not in "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789_" for c in final_name):
                     final_name = f"Card_{i:02d}_{int(time.time())}"
            
            deck_data['cards'].append({
                'index': i,
                'name': final_name,
                'x': cx,
                'y': cy
            })
            
            logger.info(f"Card {i}: {final_name}")
        
        self._save_deck(deck_data)
        return deck_data
    
    def _detect_card_positions(self, screenshot: np.ndarray) -> list:
        """
        ä½¿ç”¨è½®å»“æ£€æµ‹æ³•æ£€æµ‹å¡ç‰‡ä½ç½®
        """
        h, w = screenshot.shape[:2]
        
        # ä¿å­˜è°ƒè¯•å›¾
        cv2.imwrite("debug_screenshot_full.png", screenshot)
        
        # åŒºåŸŸæˆªå–
        x1 = int(w * self.deck_area['x_start'])
        x2 = int(w * self.deck_area['x_end'])
        y1 = int(h * self.deck_area['y_start'])
        y2 = int(h * self.deck_area['y_end'])
        
        deck_region = screenshot[y1:y2, x1:x2]
        debug_img = deck_region.copy()
        region_h, region_w = deck_region.shape[:2]
        
        # 1. é¢„å¤„ç†
        gray = cv2.cvtColor(deck_region, cv2.COLOR_BGR2GRAY)
        
        # 2. è¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(gray, 30, 100)
        
        # 3. å½¢æ€å­¦æ“ä½œ - é—­è¿ç®—è¿æ¥æ–­è£‚çš„è¾¹ç¼˜
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        closed = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel, iterations=2)
        
        # 4. æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # 5. è¿‡æ»¤è½®å»“ - æ‰¾åˆ°å¡ç‰‡å¤§å°çš„çŸ©å½¢
        est_card_w = region_w / 12
        est_card_h = region_h / 6  # æ”¹ä¸º6è¡Œï¼ˆçœ‹debugå›¾å®é™…çº¦5-6è¡Œï¼‰
        
        min_w = est_card_w * 0.4  # æ”¾å®½åˆ°0.4
        max_w = est_card_w * 2.0  # æ”¾å®½åˆ°2.0
        min_h = est_card_h * 0.4  # æ”¾å®½åˆ°0.4
        max_h = est_card_h * 2.0  # æ”¾å®½åˆ°2.0
        
        min_area = min_w * min_h * 0.5  # é™ä½æœ€å°é¢ç§¯è¦æ±‚
        
        card_rects = []
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            area = w * h
            aspect_ratio = h / w if w > 0 else 0
            
            # å¡ç‰‡åº”è¯¥æ˜¯ç«–ç›´çš„çŸ©å½¢ï¼Œé«˜åº¦>å®½åº¦
            if (min_w < w < max_w and 
                min_h < h < max_h and 
                area > min_area and
                0.8 < aspect_ratio < 2.5):  # æ”¾å®½é•¿å®½æ¯”èŒƒå›´
                card_rects.append((x, y, w, h))
        
        logger.info(f"è½®å»“æ£€æµ‹: æ‰¾åˆ° {len(contours)} ä¸ªè½®å»“, è¿‡æ»¤å {len(card_rects)} ä¸ªå¡ç‰‡")
        
        # 6. å¦‚æœè½®å»“æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨ç½‘æ ¼æ‰«æä½œä¸ºåå¤‡
        if len(card_rects) < 40:  # é™ä½é˜ˆå€¼åˆ°40
            logger.warning("è½®å»“æ£€æµ‹å¡ç‰‡æ•°é‡ä¸è¶³ï¼Œä½¿ç”¨ç½‘æ ¼æ‰«æåå¤‡æ–¹æ¡ˆ")
            card_rects = self._grid_scan_fallback(deck_region)
        
        # 7. å»é‡å¹¶æ’åº
        card_rects = self._merge_overlapping_rects(card_rects)
        
        # 8. æŒ‰è¡Œæ’åºï¼ˆä»ä¸Šåˆ°ä¸‹ï¼Œä»å·¦åˆ°å³ï¼‰
        card_rects.sort(key=lambda r: (r[1] // int(est_card_h), r[0]))
        
        # 9. è½¬æ¢ä¸ºä¸­å¿ƒç‚¹åæ ‡
        card_positions = []
        for i, (x, y, w, h) in enumerate(card_rects, 1):
            cx = x + w // 2
            cy = y + h // 2
            
            # è½¬æ¢å›å…¨å±åæ ‡
            abs_cx = x1 + cx
            abs_cy = y1 + cy
            
            card_positions.append((abs_cx, abs_cy))
            
            # è°ƒè¯•å¯è§†åŒ–
            cv2.rectangle(debug_img, (x, y), (x+w, y+h), (0, 255, 0), 2)
            cv2.putText(debug_img, str(i), (x+5, y+25), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        
        cv2.imwrite("debug_detection.png", debug_img)
        return card_positions
    
    def _grid_scan_fallback(self, deck_region: np.ndarray) -> list:
        """ç½‘æ ¼æ‰«æåå¤‡æ–¹æ¡ˆ"""
        region_h, region_w = deck_region.shape[:2]
        
        # å›ºå®šç½‘æ ¼ï¼š10åˆ— x 6è¡Œ
        cols = 10
        rows = 6
        
        card_w = region_w // cols
        card_h = region_h // rows
        
        rects = []
        for row in range(rows):
            for col in range(cols):
                x = col * card_w + card_w // 4
                y = row * card_h + card_h // 4
                w = card_w // 2
                h = card_h // 2
                
                # æ£€æŸ¥è¯¥ä½ç½®æ˜¯å¦æœ‰å†…å®¹
                roi = deck_region[y:y+h, x:x+w]
                if roi.size == 0:
                    continue
                    
                mean_intensity = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY).mean()
                if mean_intensity > 20:  # ä¸æ˜¯çº¯é»‘
                    rects.append((x, y, w, h))
        
        logger.info(f"ç½‘æ ¼æ‰«æåå¤‡: æ‰¾åˆ° {len(rects)} ä¸ªä½ç½®")
        return rects
    
    def _merge_overlapping_rects(self, rects: list) -> list:
        """åˆå¹¶é‡å çš„çŸ©å½¢"""
        if not rects:
            return []
        
        # ç®€å•çš„éæå¤§å€¼æŠ‘åˆ¶
        rects = sorted(rects, key=lambda r: r[2] * r[3], reverse=True)  # æŒ‰é¢ç§¯æ’åº
        
        merged = []
        used = [False] * len(rects)
        
        for i, (x1, y1, w1, h1) in enumerate(rects):
            if used[i]:
                continue
                
            # æ£€æŸ¥æ˜¯å¦ä¸å·²æœ‰çŸ©å½¢é‡å 
            overlap = False
            for (x2, y2, w2, h2) in merged:
                # è®¡ç®—IoU
                ix1 = max(x1, x2)
                iy1 = max(y1, y2)
                ix2 = min(x1+w1, x2+w2)
                iy2 = min(y1+h1, y2+h2)
                
                if ix1 < ix2 and iy1 < iy2:
                    inter_area = (ix2 - ix1) * (iy2 - iy1)
                    union_area = w1*h1 + w2*h2 - inter_area
                    iou = inter_area / union_area if union_area > 0 else 0
                    
                    if iou > 0.3:  # é‡å è¶…è¿‡30%
                        overlap = True
                        break
            
            if not overlap:
                merged.append((x1, y1, w1, h1))
                used[i] = True
        
        return merged
    
    
    def _recognize_card_from_detail(self, screenshot: np.ndarray) -> dict:
        """ä»å·¦ä¾§è¯¦æƒ…åŒºåŸŸè¯†åˆ«å¡ç‰‡"""
        h, w = screenshot.shape[:2]
        
        # æå–è¯¦æƒ…åŒºåŸŸ
        x1 = int(w * self.detail_area['x'])
        y1 = int(h * self.detail_area['y'])
        w_detail = int(w * self.detail_area['width'])
        h_detail = int(h * self.detail_area['height'])
        
        detail_img = screenshot[y1:y1+h_detail, x1:x1+w_detail]
        
        # æ–¹æ³•1ï¼šå›¾åƒè¯†åˆ«
        if len(self.recognizer.card_templates) > 0:
            result = self.recognizer.recognize_card(detail_img)
            if result and result['confidence'] > 0.7:
                # ä¿å­˜æ¨¡æ¿
                self._save_template(detail_img, result['name'])
                return result
        
        # æ–¹æ³•2ï¼šOCRè¯†åˆ«å¡å
        card_name = self._ocr_card_name(screenshot)
        
        if card_name:
            # ä¿å­˜æ¨¡æ¿
            self._save_template(detail_img, card_name)
            return {'name': card_name, 'confidence': 0.8, 'method': 'ocr'}
        
        # éƒ½å¤±è´¥äº†ï¼Œè‡³å°‘ä¿å­˜å›¾åƒ
        self._save_template(detail_img, f"unknown_{int(time.time())}")
        
        return None
    
    def _ocr_card_name(self, screenshot: np.ndarray) -> str:
        """OCRè¯†åˆ«å¡ç‰‡åç§°"""
        try:
            import pytesseract
            import re
            
            h, w = screenshot.shape[:2]
            
            # ç­–ç•¥ï¼šä½¿ç”¨é¢œè‰²æ£€æµ‹æ‰¾åˆ°ç´«è‰²æ ‡é¢˜æ 
            hsv = cv2.cvtColor(screenshot, cv2.COLOR_BGR2HSV)
            
            # æ£€æµ‹ç´«è‰²èŒƒå›´ï¼ˆH: 280-320åº¦ -> 140-160ï¼‰
            lower_purple = np.array([140, 50, 50])
            upper_purple = np.array([160, 255, 255])
            purple_mask = cv2.inRange(hsv, lower_purple, upper_purple)
            
            # å½¢æ€å­¦æ“ä½œå»å™ª
            kernel = np.ones((5, 5), np.uint8)
            purple_mask = cv2.morphologyEx(purple_mask, cv2.MORPH_CLOSE, kernel)
            purple_mask = cv2.morphologyEx(purple_mask, cv2.MORPH_OPEN, kernel)
            
            # æ‰¾åˆ°æœ€å¤§çš„ç´«è‰²åŒºåŸŸ
            contours, _ = cv2.findContours(purple_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if not contours:
                logger.debug("æœªæ£€æµ‹åˆ°ç´«è‰²æ ‡é¢˜æ ï¼Œä½¿ç”¨é»˜è®¤åŒºåŸŸ")
                name_x = int(w * 0.015)
                name_y = int(h * 0.055)
                name_w = int(w * 0.35)
                name_h = int(h * 0.055)
                name_img = screenshot[name_y:name_y+name_h, name_x:name_x+name_w]
            else:
                # æ‰¾åˆ°æœ€å¤§çš„ç´«è‰²è½®å»“ï¼ˆåº”è¯¥æ˜¯æ ‡é¢˜æ ï¼‰
                largest_contour = max(contours, key=cv2.contourArea)
                x, y, w_box, h_box = cv2.boundingRect(largest_contour)
                
                logger.debug(f"æ£€æµ‹åˆ°ç´«è‰²åŒºåŸŸ: x={x}, y={y}, w={w_box}, h={h_box}")
                
                # è£å‰ªå‡ºç´«è‰²æ ‡é¢˜æ ï¼ˆåŠ ä¸€ç‚¹paddingï¼‰
                pad = 5
                name_x = max(0, x - pad)
                name_y = max(0, y - pad)
                name_w = min(w - name_x, w_box + 2*pad)
                name_h = min(h - name_y, h_box + 2*pad)
                
                name_img = screenshot[name_y:name_y+name_h, name_x:name_x+name_w]
            
            # ä¿å­˜è°ƒè¯•å›¾
            debug_path = f"debug_ocr_{int(time.time()*1000)}.png"
            cv2.imwrite(debug_path, name_img)
            
            # é¢„å¤„ç†ç®¡çº¿
            # å…³é”®ï¼šç´«è‰²èƒŒæ™¯ + ç™½è‰²æ–‡å­—
            # ç­–ç•¥1ï¼šä½¿ç”¨HSVé¢œè‰²ç©ºé—´æå–ç™½è‰²æ–‡å­—
            hsv = cv2.cvtColor(name_img, cv2.COLOR_BGR2HSV)
            
            # ç™½è‰²èŒƒå›´ï¼ˆé«˜äº®åº¦ï¼Œä½é¥±å’Œåº¦ï¼‰
            lower_white = np.array([0, 0, 200])
            upper_white = np.array([180, 30, 255])
            white_mask = cv2.inRange(hsv, lower_white, upper_white)
            
            # åº”ç”¨mask
            white_text = cv2.bitwise_and(name_img, name_img, mask=white_mask)
            gray = cv2.cvtColor(white_text, cv2.COLOR_BGR2GRAY)
            
            # 1. æ”¾å¤§ (4å€)
            scale = 4
            scaled = cv2.resize(gray, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)
            
            # 2. åè½¬ï¼ˆè®©æ–‡å­—å˜æˆé»‘è‰²ï¼‰
            inverted = cv2.bitwise_not(scaled)
            
            # 3. äºŒå€¼åŒ–
            _, binary = cv2.threshold(inverted, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # 4. é™å™ª
            denoised = cv2.medianBlur(binary, 3)
            
            candidates = [denoised]
            
            # ç­–ç•¥2ï¼šä¹Ÿè¯•è¯•ç›´æ¥è½¬ç°åº¦
            gray_direct = cv2.cvtColor(name_img, cv2.COLOR_BGR2GRAY)
            scaled2 = cv2.resize(gray_direct, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)
            _, bin2 = cv2.threshold(scaled2, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            candidates.append(bin2)

            best_name = ""
            max_len = 0
            
            for i, binary in enumerate(candidates):
                # OCR é…ç½®ä¼˜åŒ–ï¼šä½¿ç”¨LSTM OCRå¼•æ“(oem 1)ï¼Œå•è¡Œæ–‡æœ¬æ¨¡å¼(psm 7)
                name = pytesseract.image_to_string(
                    binary,
                    lang='chi_sim+eng',  # åŒæ—¶æ”¯æŒä¸­æ–‡å’Œè‹±æ–‡
                    config='--oem 1 --psm 7 -c preserve_interword_spaces=0'
                ).strip()
                
                # æ¸…æ´—å­—ç¬¦ï¼šåªä¿ç•™ä¸­æ–‡ã€æ•°å­—ã€è‹±æ–‡å­—æ¯ã€å¸¸è§æ ‡ç‚¹
                # unicodeèŒƒå›´: \u4e00-\u9fa5 (ä¸­æ–‡æ±‰å­—)
                clean_name = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9Â·â€¢ã€ï¼Œã€‚ï¼ï¼Ÿ]', '', name)
                
                logger.debug(f"OCRå€™é€‰ {i+1}: raw='{name}' -> clean='{clean_name}'")
                
                if len(clean_name) > max_len:
                    max_len = len(clean_name)
                    best_name = clean_name
            
            # é¢å¤–éªŒè¯ï¼šå¦‚æœè¯†åˆ«ç»“æœå¤ªçŸ­æˆ–å¤ªé•¿ï¼Œå¯èƒ½æ˜¯é”™è¯¯çš„
            if best_name and 2 <= len(best_name) <= 25:
                return best_name
                
        except Exception as e:
            logger.debug(f"OCRå¤±è´¥: {e}")
        
        return None
    
    def _save_template(self, card_img: np.ndarray, card_name: str):
        """ä¿å­˜å¡ç‰‡æ¨¡æ¿"""
        # æå–è‰ºæœ¯å›¾éƒ¨åˆ†
        h, w = card_img.shape[:2]
        art_h = int(h * 0.6)
        art_img = card_img[0:art_h, :]
        
        card_id = str(abs(hash(card_name)) % 10000000)
        
        template_dir = Path("data/templates")
        template_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜å›¾åƒ
        img_path = template_dir / f"{card_id}.png"
        cv2.imwrite(str(img_path), art_img)
        
        # ä¿å­˜å…ƒæ•°æ®
        meta_path = template_dir / f"{card_id}.json"
        metadata = {
            'card_id': card_id,
            'name': card_name,
            'auto_scanned': True,
            'smart_scan': True
        }
        with open(meta_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
    
    def _save_deck(self, deck_data: dict):
        """ä¿å­˜å¡ç»„æ•°æ®"""
        output_dir = Path("data/decks")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        filename = f"{deck_data['deck_name']}.json"
        filepath = output_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(deck_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"âœ… å¡ç»„å·²ä¿å­˜: {filepath}")
        logger.info(f"ğŸ“Š æ€»è®¡: {len(deck_data['cards'])} å¼ å¡ç‰‡")


# ä¸»ç¨‹åº
if __name__ == "__main__":
    print("=" * 60)
    print("æ™ºèƒ½å¡ç»„æ‰«æå™¨ V2.0 ğŸ¤–")
    print("=" * 60)
    print()
    print("âœ¨ æ–°ç‰¹æ€§:")
    print("  - è‡ªåŠ¨æ£€æµ‹å¡ç‰‡ä½ç½®ï¼Œæ— éœ€å›ºå®šåæ ‡")
    print("  - é€‚åº”ä»»ä½•å¡ç»„æ•°é‡ï¼ˆä¸»å¡ç»„+é¢å¤–å¡ç»„ï¼‰")
    print("  - è‡ªåŠ¨æŒ‰é¡ºåºæ‰«æ")
    print()
    print("ğŸ“‹ ä½¿ç”¨è¯´æ˜:")
    print("1. å¯åŠ¨æ¸¸æˆå¹¶è¿›å…¥å¡ç»„ç¼–è¾‘ç•Œé¢")
    print("2. ç¡®ä¿å¡ç»„å®Œå…¨å¯è§")
    print("3. ä¸è¦ç§»åŠ¨é¼ æ ‡ï¼Œè®©Botè‡ªåŠ¨æ“ä½œ")
    print()
    
    deck_name = input("è¯·è¾“å…¥å¡ç»„åç§°: ").strip()
    if not deck_name:
        deck_name = f"deck_{int(time.time())}"
    
    print()
    print("å‡†å¤‡å¼€å§‹...")
    input("æŒ‰Enterå¼€å§‹æ‰«æ...")
    
    scanner = SmartDeckScanner()
    result = scanner.scan_deck(deck_name)
    
    if result:
        print()
        print("=" * 60)
        print("âœ… æ‰«æå®Œæˆï¼")
        print("=" * 60)
        print(f"ğŸ“¦ å¡ç»„: {result['deck_name']}")
        print(f"ğŸ“Š å¡ç‰‡æ•°: {len(result['cards'])}")
        print()
        print("ğŸ’¾ å·²ä¿å­˜:")
        print(f"  - å¡ç»„æ•°æ®: data/decks/{result['deck_name']}.json")
        print(f"  - å¡ç‰‡æ¨¡æ¿: data/templates/")
        print()
        
        # æ˜¾ç¤ºè¯†åˆ«çš„å¡ç‰‡
        print("è¯†åˆ«çš„å¡ç‰‡:")
        for i, card in enumerate(result['cards'][:10], 1):  # åªæ˜¾ç¤ºå‰10å¼ 
            print(f"  {i}. {card['name']}")
        if len(result['cards']) > 10:
            print(f"  ... è¿˜æœ‰ {len(result['cards']) - 10} å¼ ")
